# harm_detection_via_sparse_latents

problem motivation: Harmful Adversial Prompt Detection

<img width="772" alt="image" src="https://github.com/user-attachments/assets/460b382c-dcd9-4a1c-afde-a49a8b524b81" />


Research Question: can we detect harmful prompts via internal representation of language models?

In simple terms, 

related fields

This project investigate


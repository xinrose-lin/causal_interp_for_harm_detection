# harm_detection_via_sparse_latents

capstone project: can we locate model internal representation of harm for harmful prompt detection?
